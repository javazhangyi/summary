9-切片集群
  如何保存更多的数据
    纵向升级：升级单个节点的配置
      优点）管理实施简单，缺点）数据较大时候，可能出现性能问题，而且受硬件限制
    横向扩展：增加redis的数据数目
      优点）不受硬件限制，缺点）维护成本大

      需要解决的问题
        数据切片后，多个实例如何分布：请求路由
          redis-cluster：通过hash slot，数据被分为16000多个区，每一个key，通过CRC-16生成16bit 在取模16383 被映射到一个区间
            通过cluster create，自动将slot 映射到 实例上，（需要手动吧slot分配完，否则无法正常工作）

        客户端如何确定访问的数据在哪一个实例上
          节点会把自己拥有的hash slot 通知给其他实例，当客户端请求某一个节点后，会会获取所有的slot信息，然后客户端自己计算一个key 对象的slot，就知道在哪一个节点上

        实例和slot变化：数据迁移
          实例节点增加或者减少，redis会重新分配节点
          为了负载均衡会重新分配slot
        存在的问题：节点可以相互传递slot 变化信息，但是客户端无法知道
        解决方法：重定向机制，当客户端请求节点没有信息，该节点就会放回新实例节点的访问地址（通过moved命令表示）
        存在的问题：slot已经转移一部分
        解决方法：放回ask，客户端给实例发送asking（表示slot，停下执行可自己的命令）然后发送get请求获取数据


集群的管理问题
    请求路由
    数据迁移


Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？
    可以的数量太多，映射关系复杂
    在数据迁移，维护成本比较高
    切片是去中心化